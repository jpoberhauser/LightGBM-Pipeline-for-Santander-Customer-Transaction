{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* if the feature are category feature, you can do this easily. calculate each class's target mean and use the mean as a column!\n",
    "\n",
    "* http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging/target-encoding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                # :kaggle: 0.899\n",
    "# :here: 0.8971399999999999\n",
    "\n",
    "\n",
    "# best so far:\n",
    "# params = {\n",
    "#     'min_child_weight': 10.0,\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'max_depth': 3,\n",
    "#     'max_delta_step': 1.8,\n",
    "#     'colsample_bytree': 0.4,\n",
    "#     'subsample': 0.8,\n",
    "#     'eta': 0.05,\n",
    "#     'gamma': 0.65,\n",
    "#     'num_boost_round' : 700,\n",
    "#     'tree_method':'approx',\n",
    "#      \"eval_metric\": \"auc\"\n",
    "#     }\n",
    "\n",
    "# for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "#     print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "#     X_train, X_valid = X[train_index], X[test_index]\n",
    "#     y_train, y_valid = y[train_index], y[test_index]\n",
    "#     # Convert our data into XGBoost format\n",
    "#     d_train = xgb.DMatrix(X_train, y_train)\n",
    "#     d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "#     d_test = xgb.DMatrix(test.values)\n",
    "#     watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "#     mdl = xgb.train(params, d_train, 3000, watchlist, early_stopping_rounds=90, maximize=True, verbose_eval=100)\n",
    "\n",
    "#     print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n",
    "#     # Predict on our test data\n",
    "#     p_test = mdl.predict(d_test, ntree_limit=mdl.best_ntree_limit)\n",
    "#     sub['target'] += p_test/kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('train_NEWFEATURES.csv')\n",
    "# train = train.drop(['Unnamed: 0'],axis=1)\n",
    "# test = pd.read_csv('test_NEWFEATURES.csv')\n",
    "# test = test.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/santander-customer-transaction-prediction/train.csv')\n",
    "test = pd.read_csv('data/santander-customer-transaction-prediction/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "for feature in features:\n",
    "    train['r2_'+feature] = np.round(train[feature], 2)\n",
    "    test['r2_'+feature] = np.round(test[feature], 2)\n",
    "    train['r1_'+feature] = np.round(train[feature], 1)\n",
    "    test['r1_'+feature] = np.round(test[feature], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.target\n",
    "X = train.drop(['ID_code', 'target'], axis=1)\n",
    "X_test = test.drop(['ID_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "d_test = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build a benchmark\n",
    "\n",
    "1. selection of features\n",
    "\n",
    "2. chossing performance metric\n",
    "\n",
    "3. choosing a classifier and optimization algorithm\n",
    "\n",
    "4. evaluate the performance of the model\n",
    "\n",
    "5. tuning the algorithm\n",
    "\n",
    "*Area under receiver operating curve*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppn = Perceptron(max_iter=5000, eta0=0.01, random_state=1)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ppn.predict(X_valid_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=-1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                n_estimators=150, \n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = forest.predict(X_valid)\n",
    "roc_auc_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =10\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(d_train,'train'), (d_valid,'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.581086\tvalid-auc:0.573249\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 100 rounds.\n",
      "[100]\ttrain-auc:0.808019\tvalid-auc:0.7924\n",
      "[200]\ttrain-auc:0.853744\tvalid-auc:0.832053\n",
      "[300]\ttrain-auc:0.875797\tvalid-auc:0.850153\n",
      "[400]\ttrain-auc:0.889721\tvalid-auc:0.861636\n",
      "[500]\ttrain-auc:0.899114\tvalid-auc:0.869153\n",
      "[600]\ttrain-auc:0.906544\tvalid-auc:0.875061\n",
      "[700]\ttrain-auc:0.912194\tvalid-auc:0.878935\n",
      "[800]\ttrain-auc:0.91696\tvalid-auc:0.882651\n",
      "[900]\ttrain-auc:0.920868\tvalid-auc:0.885173\n",
      "[999]\ttrain-auc:0.924322\tvalid-auc:0.887392\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting':'dart',\n",
    "    'min_child_weight': 10.0,\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 3,\n",
    "    'max_delta_step': 1.8,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'subsample': 0.8,\n",
    "    'eta': 0.045,\n",
    "    'gamma': 0.65,\n",
    "    'num_boost_round' : 700,\n",
    "    'tree_method':'approx',\n",
    "     \"eval_metric\": \"auc\"\n",
    "    }\n",
    "\n",
    "mdl = xgb.train(params, d_train, 1000, watchlist, early_stopping_rounds=100, maximize=True, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorization Machines are probably a great candidate for this\n",
    "* https://www.analyticsvidhya.com/blog/2018/01/factorization-machines/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code target\n",
       "0  test_0    NaN\n",
       "1  test_1    NaN\n",
       "2  test_2    NaN\n",
       "3  test_3    NaN\n",
       "4  test_4    NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnId = 'ID_code'\n",
    "columnTarget = 'target'\n",
    "sub = pd.DataFrame(test[columnId], columns=[columnId,columnTarget])\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mdl.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[columnTarget]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.085930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.245788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.157744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.145868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.044896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    target\n",
       "0  test_0  0.085930\n",
       "1  test_1  0.245788\n",
       "2  test_2  0.157744\n",
       "3  test_3  0.145868\n",
       "4  test_4  0.044896"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Booster'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submitPR_{}.csv'.format(mdl.__class__.__name__), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submissionFile(clf):\n",
    "    print('Creating submission file')\n",
    "    pred = clf.predict(features) \n",
    "    sub[columnTarget]=pred\n",
    "    print('submit_{}.csv'.format(clf.__class__.__name__))\n",
    "    sub.to_csv('submit_{}.csv'.format(clf.__class__.__name__), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/sudosudoohio/stratified-kfold-xgboost-eda-tutorial-0-281\n",
    "X = train.drop(['ID_code', 'target'], axis=1).values\n",
    "X_for_aug = train\n",
    "y = train.target.values\n",
    "X_test = test.drop(['ID_code'], axis=1)\n",
    "test_id = test.ID_code.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>r2_var_195</th>\n",
       "      <th>r1_var_195</th>\n",
       "      <th>r2_var_196</th>\n",
       "      <th>r1_var_196</th>\n",
       "      <th>r2_var_197</th>\n",
       "      <th>r1_var_197</th>\n",
       "      <th>r2_var_198</th>\n",
       "      <th>r1_var_198</th>\n",
       "      <th>r2_var_199</th>\n",
       "      <th>r1_var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.72</td>\n",
       "      <td>10.7</td>\n",
       "      <td>15.47</td>\n",
       "      <td>15.5</td>\n",
       "      <td>-8.72</td>\n",
       "      <td>-8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>9.87</td>\n",
       "      <td>9.9</td>\n",
       "      <td>19.13</td>\n",
       "      <td>19.1</td>\n",
       "      <td>-20.98</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>...</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-7.11</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>7.06</td>\n",
       "      <td>7.1</td>\n",
       "      <td>19.90</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-23.18</td>\n",
       "      <td>-23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>...</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>9.2</td>\n",
       "      <td>13.02</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-4.21</td>\n",
       "      <td>-4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-5.16</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>7.29</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13.93</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-9.18</td>\n",
       "      <td>-9.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0    var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
       "1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
       "2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.2537   \n",
       "3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.5660   \n",
       "4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.6048   \n",
       "\n",
       "    var_8   var_9  ...  r2_var_195  r1_var_195  r2_var_196  r1_var_196  \\\n",
       "0  2.1337  8.8100  ...        2.47         2.5        4.37         4.4   \n",
       "1 -4.4131  5.9739  ...        0.48         0.5       -1.49        -1.5   \n",
       "2  1.5233  8.3442  ...        2.13         2.1       -7.11        -7.1   \n",
       "3  3.3755  7.4578  ...        3.17         3.2        3.96         4.0   \n",
       "4  2.9890  7.1437  ...       -0.29        -0.3       -5.16        -5.2   \n",
       "\n",
       "   r2_var_197  r1_var_197  r2_var_198  r1_var_198  r2_var_199  r1_var_199  \n",
       "0       10.72        10.7       15.47        15.5       -8.72        -8.7  \n",
       "1        9.87         9.9       19.13        19.1      -20.98       -21.0  \n",
       "2        7.06         7.1       19.90        19.9      -23.18       -23.2  \n",
       "3        9.23         9.2       13.02        13.0       -4.21        -4.2  \n",
       "4        7.29         7.3       13.93        13.9       -9.18        -9.2  \n",
       "\n",
       "[5 rows x 600 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'min_child_weight': 10.0,\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 5,\n",
    "    'max_delta_step': 1.8,\n",
    "    'colsample_bytree': 0.2,\n",
    "    'subsample': 0.6,\n",
    "    'eta': 0.01,\n",
    "    'gamma': 0.65,\n",
    "    'num_boost_round' : 700,\n",
    "    'tree_method':'approx',\n",
    "     \"eval_metric\": \"auc\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspiration from\n",
    "#https://www.kaggle.com/jiweiliu/lgb-2-leaves-augment\n",
    "def augment(train,num_n=1,num_p=2):\n",
    "    newtrain=[train]\n",
    "    \n",
    "    n=train[train.target==0]\n",
    "    for i in range(num_n):\n",
    "        newtrain.append(n.apply(lambda x:x.values.take(np.random.permutation(len(n)))))\n",
    "    \n",
    "    for i in range(num_p):\n",
    "        p=train[train.target>0]\n",
    "        newtrain.append(p.apply(lambda x:x.values.take(np.random.permutation(len(p)))))\n",
    "    return pd.concat(newtrain)\n",
    "#df=oversample(train,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = np.zeros_like(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id target\n",
       "0  test_0      0\n",
       "1  test_1      0\n",
       "2  test_2      0\n",
       "3  test_3      0\n",
       "4  test_4      0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 600)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5]\n",
      "[0]\ttrain-auc:0.626438\tvalid-auc:0.617105\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 300 rounds.\n",
      "[100]\ttrain-auc:0.807371\tvalid-auc:0.721957\n",
      "[200]\ttrain-auc:0.835762\tvalid-auc:0.74569\n",
      "[300]\ttrain-auc:0.857091\tvalid-auc:0.765577\n",
      "[400]\ttrain-auc:0.876367\tvalid-auc:0.786151\n",
      "[500]\ttrain-auc:0.889724\tvalid-auc:0.800329\n",
      "[600]\ttrain-auc:0.89985\tvalid-auc:0.811542\n",
      "[700]\ttrain-auc:0.907293\tvalid-auc:0.819928\n",
      "[800]\ttrain-auc:0.914131\tvalid-auc:0.827884\n",
      "[900]\ttrain-auc:0.919331\tvalid-auc:0.833893\n",
      "[1000]\ttrain-auc:0.923953\tvalid-auc:0.839344\n",
      "[1100]\ttrain-auc:0.927784\tvalid-auc:0.843478\n",
      "[1200]\ttrain-auc:0.931429\tvalid-auc:0.847589\n",
      "[1300]\ttrain-auc:0.93457\tvalid-auc:0.850854\n",
      "[1400]\ttrain-auc:0.937605\tvalid-auc:0.853948\n",
      "[1500]\ttrain-auc:0.940198\tvalid-auc:0.856625\n",
      "[1600]\ttrain-auc:0.942598\tvalid-auc:0.858918\n",
      "[1700]\ttrain-auc:0.944577\tvalid-auc:0.861067\n",
      "[1800]\ttrain-auc:0.946619\tvalid-auc:0.86315\n",
      "[1900]\ttrain-auc:0.948307\tvalid-auc:0.86487\n",
      "[2000]\ttrain-auc:0.949957\tvalid-auc:0.866606\n",
      "[2100]\ttrain-auc:0.951424\tvalid-auc:0.868041\n",
      "[2200]\ttrain-auc:0.952838\tvalid-auc:0.869542\n",
      "[2300]\ttrain-auc:0.954183\tvalid-auc:0.870874\n",
      "[2400]\ttrain-auc:0.955368\tvalid-auc:0.87215\n",
      "[2500]\ttrain-auc:0.95653\tvalid-auc:0.873392\n",
      "[2600]\ttrain-auc:0.957579\tvalid-auc:0.874413\n",
      "[2700]\ttrain-auc:0.958599\tvalid-auc:0.875483\n",
      "[2800]\ttrain-auc:0.959554\tvalid-auc:0.876472\n",
      "[2900]\ttrain-auc:0.960443\tvalid-auc:0.877418\n",
      "[3000]\ttrain-auc:0.961261\tvalid-auc:0.878335\n",
      "[3100]\ttrain-auc:0.962059\tvalid-auc:0.879137\n",
      "[3200]\ttrain-auc:0.962806\tvalid-auc:0.879886\n",
      "[3300]\ttrain-auc:0.96353\tvalid-auc:0.880623\n",
      "[3400]\ttrain-auc:0.964254\tvalid-auc:0.881345\n",
      "[3500]\ttrain-auc:0.964891\tvalid-auc:0.881996\n",
      "[3600]\ttrain-auc:0.965523\tvalid-auc:0.882629\n",
      "[3700]\ttrain-auc:0.9661\tvalid-auc:0.883157\n",
      "[3800]\ttrain-auc:0.966671\tvalid-auc:0.88366\n",
      "[3900]\ttrain-auc:0.967246\tvalid-auc:0.884224\n",
      "[4000]\ttrain-auc:0.967782\tvalid-auc:0.884795\n",
      "[4100]\ttrain-auc:0.968313\tvalid-auc:0.885288\n",
      "[4200]\ttrain-auc:0.968811\tvalid-auc:0.885752\n",
      "[4300]\ttrain-auc:0.969299\tvalid-auc:0.886191\n",
      "[4400]\ttrain-auc:0.969766\tvalid-auc:0.886716\n",
      "[4500]\ttrain-auc:0.970218\tvalid-auc:0.887138\n",
      "[4600]\ttrain-auc:0.970635\tvalid-auc:0.887606\n",
      "[4700]\ttrain-auc:0.971081\tvalid-auc:0.888007\n",
      "[4800]\ttrain-auc:0.971492\tvalid-auc:0.888381\n",
      "[4900]\ttrain-auc:0.971896\tvalid-auc:0.88873\n",
      "[5000]\ttrain-auc:0.972302\tvalid-auc:0.889089\n",
      "[5100]\ttrain-auc:0.972653\tvalid-auc:0.889408\n",
      "[5200]\ttrain-auc:0.973009\tvalid-auc:0.889754\n",
      "[5300]\ttrain-auc:0.973344\tvalid-auc:0.890067\n",
      "[5400]\ttrain-auc:0.9737\tvalid-auc:0.890413\n",
      "[5500]\ttrain-auc:0.974038\tvalid-auc:0.890691\n",
      "[5600]\ttrain-auc:0.974371\tvalid-auc:0.890974\n",
      "[5700]\ttrain-auc:0.974697\tvalid-auc:0.891229\n",
      "[5800]\ttrain-auc:0.975006\tvalid-auc:0.891478\n",
      "[5900]\ttrain-auc:0.975312\tvalid-auc:0.891734\n",
      "[6000]\ttrain-auc:0.975598\tvalid-auc:0.891982\n",
      "[6100]\ttrain-auc:0.975868\tvalid-auc:0.892198\n",
      "[6200]\ttrain-auc:0.976149\tvalid-auc:0.892422\n",
      "[6300]\ttrain-auc:0.976436\tvalid-auc:0.892637\n",
      "[6400]\ttrain-auc:0.976706\tvalid-auc:0.892806\n",
      "[6500]\ttrain-auc:0.976978\tvalid-auc:0.892986\n",
      "[6600]\ttrain-auc:0.977232\tvalid-auc:0.893202\n",
      "[6700]\ttrain-auc:0.977461\tvalid-auc:0.893368\n",
      "[6800]\ttrain-auc:0.977704\tvalid-auc:0.893497\n",
      "[6900]\ttrain-auc:0.977945\tvalid-auc:0.893654\n",
      "[7000]\ttrain-auc:0.978162\tvalid-auc:0.893842\n",
      "[7100]\ttrain-auc:0.978392\tvalid-auc:0.894033\n",
      "[7200]\ttrain-auc:0.978621\tvalid-auc:0.894188\n",
      "[7300]\ttrain-auc:0.978846\tvalid-auc:0.89435\n",
      "[7400]\ttrain-auc:0.979073\tvalid-auc:0.894533\n",
      "[7500]\ttrain-auc:0.979286\tvalid-auc:0.894664\n",
      "[7600]\ttrain-auc:0.979503\tvalid-auc:0.894774\n",
      "[7700]\ttrain-auc:0.979709\tvalid-auc:0.89492\n",
      "[7800]\ttrain-auc:0.979906\tvalid-auc:0.895058\n",
      "[7900]\ttrain-auc:0.980096\tvalid-auc:0.895185\n",
      "[8000]\ttrain-auc:0.980301\tvalid-auc:0.895298\n",
      "[8100]\ttrain-auc:0.9805\tvalid-auc:0.895406\n",
      "[8200]\ttrain-auc:0.980693\tvalid-auc:0.895509\n",
      "[8300]\ttrain-auc:0.980886\tvalid-auc:0.89563\n",
      "[8400]\ttrain-auc:0.981077\tvalid-auc:0.895742\n",
      "[8500]\ttrain-auc:0.981268\tvalid-auc:0.895808\n",
      "[8600]\ttrain-auc:0.981447\tvalid-auc:0.895893\n",
      "[8700]\ttrain-auc:0.981629\tvalid-auc:0.895995\n",
      "[8800]\ttrain-auc:0.981807\tvalid-auc:0.896091\n",
      "[8900]\ttrain-auc:0.981976\tvalid-auc:0.896183\n",
      "[9000]\ttrain-auc:0.98215\tvalid-auc:0.89628\n",
      "[9100]\ttrain-auc:0.98232\tvalid-auc:0.89635\n",
      "[9200]\ttrain-auc:0.982488\tvalid-auc:0.896405\n",
      "[9300]\ttrain-auc:0.982647\tvalid-auc:0.896471\n",
      "[9400]\ttrain-auc:0.982817\tvalid-auc:0.896518\n",
      "[9500]\ttrain-auc:0.982973\tvalid-auc:0.896584\n",
      "[9600]\ttrain-auc:0.983131\tvalid-auc:0.896619\n",
      "[9700]\ttrain-auc:0.983298\tvalid-auc:0.896681\n",
      "[9800]\ttrain-auc:0.983461\tvalid-auc:0.896726\n",
      "[9900]\ttrain-auc:0.983623\tvalid-auc:0.89677\n",
      "[10000]\ttrain-auc:0.983775\tvalid-auc:0.896834\n",
      "[10100]\ttrain-auc:0.983926\tvalid-auc:0.896905\n",
      "[10200]\ttrain-auc:0.984074\tvalid-auc:0.89691\n",
      "[10300]\ttrain-auc:0.984222\tvalid-auc:0.896966\n",
      "[10400]\ttrain-auc:0.984365\tvalid-auc:0.897043\n",
      "[10500]\ttrain-auc:0.984504\tvalid-auc:0.897083\n",
      "[10600]\ttrain-auc:0.984645\tvalid-auc:0.897112\n",
      "[10700]\ttrain-auc:0.984796\tvalid-auc:0.897163\n",
      "[10800]\ttrain-auc:0.984937\tvalid-auc:0.89722\n",
      "[10900]\ttrain-auc:0.985078\tvalid-auc:0.897225\n",
      "[11000]\ttrain-auc:0.985216\tvalid-auc:0.89729\n",
      "[11100]\ttrain-auc:0.985354\tvalid-auc:0.897323\n",
      "[11200]\ttrain-auc:0.985492\tvalid-auc:0.897343\n",
      "[11300]\ttrain-auc:0.985631\tvalid-auc:0.89734\n",
      "[11400]\ttrain-auc:0.985767\tvalid-auc:0.897372\n",
      "[11500]\ttrain-auc:0.985908\tvalid-auc:0.897395\n",
      "[11600]\ttrain-auc:0.986031\tvalid-auc:0.897421\n",
      "[11700]\ttrain-auc:0.986155\tvalid-auc:0.897444\n",
      "[11800]\ttrain-auc:0.986288\tvalid-auc:0.89746\n",
      "[11900]\ttrain-auc:0.986422\tvalid-auc:0.897505\n",
      "[12000]\ttrain-auc:0.986554\tvalid-auc:0.897523\n",
      "[12100]\ttrain-auc:0.986683\tvalid-auc:0.897549\n",
      "[12200]\ttrain-auc:0.986819\tvalid-auc:0.897585\n",
      "[12300]\ttrain-auc:0.986942\tvalid-auc:0.897621\n",
      "[12400]\ttrain-auc:0.98707\tvalid-auc:0.897635\n",
      "[12500]\ttrain-auc:0.987188\tvalid-auc:0.897647\n",
      "[12600]\ttrain-auc:0.987313\tvalid-auc:0.897678\n",
      "[12700]\ttrain-auc:0.987438\tvalid-auc:0.897679\n",
      "[12800]\ttrain-auc:0.987572\tvalid-auc:0.897699\n",
      "[12900]\ttrain-auc:0.987695\tvalid-auc:0.897693\n",
      "[13000]\ttrain-auc:0.987817\tvalid-auc:0.897692\n",
      "[13100]\ttrain-auc:0.98794\tvalid-auc:0.897705\n",
      "[13200]\ttrain-auc:0.988066\tvalid-auc:0.897722\n",
      "[13300]\ttrain-auc:0.988183\tvalid-auc:0.897736\n",
      "[13400]\ttrain-auc:0.988295\tvalid-auc:0.89775\n",
      "[13500]\ttrain-auc:0.988419\tvalid-auc:0.897758\n",
      "[13600]\ttrain-auc:0.988541\tvalid-auc:0.897753\n",
      "[13700]\ttrain-auc:0.988662\tvalid-auc:0.897776\n",
      "[13800]\ttrain-auc:0.988777\tvalid-auc:0.897769\n",
      "[13900]\ttrain-auc:0.988891\tvalid-auc:0.897788\n",
      "[14000]\ttrain-auc:0.989007\tvalid-auc:0.897783\n",
      "[14100]\ttrain-auc:0.989128\tvalid-auc:0.897762\n",
      "[14200]\ttrain-auc:0.989252\tvalid-auc:0.897767\n",
      "Stopping. Best iteration:\n",
      "[13965]\ttrain-auc:0.988965\tvalid-auc:0.897796\n",
      "\n",
      "[Fold 1/5 Prediciton:]\n",
      "[Fold 2/5]\n",
      "[0]\ttrain-auc:0.618663\tvalid-auc:0.622624\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 300 rounds.\n",
      "[100]\ttrain-auc:0.805195\tvalid-auc:0.716091\n",
      "[200]\ttrain-auc:0.833813\tvalid-auc:0.740359\n",
      "[300]\ttrain-auc:0.857036\tvalid-auc:0.764132\n",
      "[400]\ttrain-auc:0.876102\tvalid-auc:0.784259\n",
      "[500]\ttrain-auc:0.889989\tvalid-auc:0.799408\n",
      "[600]\ttrain-auc:0.899846\tvalid-auc:0.810658\n",
      "[700]\ttrain-auc:0.907596\tvalid-auc:0.820047\n",
      "[800]\ttrain-auc:0.914147\tvalid-auc:0.827623\n",
      "[900]\ttrain-auc:0.919313\tvalid-auc:0.833957\n",
      "[1000]\ttrain-auc:0.923793\tvalid-auc:0.839218\n",
      "[1100]\ttrain-auc:0.927656\tvalid-auc:0.843607\n",
      "[1200]\ttrain-auc:0.931314\tvalid-auc:0.847695\n",
      "[1300]\ttrain-auc:0.934387\tvalid-auc:0.851152\n",
      "[1400]\ttrain-auc:0.937243\tvalid-auc:0.854279\n",
      "[1500]\ttrain-auc:0.940009\tvalid-auc:0.857429\n",
      "[1600]\ttrain-auc:0.942326\tvalid-auc:0.859879\n",
      "[1700]\ttrain-auc:0.944419\tvalid-auc:0.862111\n",
      "[1800]\ttrain-auc:0.946351\tvalid-auc:0.864082\n",
      "[1900]\ttrain-auc:0.948156\tvalid-auc:0.865987\n",
      "[2000]\ttrain-auc:0.949792\tvalid-auc:0.867678\n",
      "[2100]\ttrain-auc:0.95133\tvalid-auc:0.869236\n",
      "[2200]\ttrain-auc:0.952764\tvalid-auc:0.870644\n",
      "[2300]\ttrain-auc:0.954053\tvalid-auc:0.872024\n",
      "[2400]\ttrain-auc:0.955263\tvalid-auc:0.873183\n",
      "[2500]\ttrain-auc:0.956411\tvalid-auc:0.874357\n",
      "[2600]\ttrain-auc:0.957464\tvalid-auc:0.875476\n",
      "[2700]\ttrain-auc:0.958458\tvalid-auc:0.876482\n",
      "[2800]\ttrain-auc:0.959421\tvalid-auc:0.877456\n",
      "[2900]\ttrain-auc:0.960335\tvalid-auc:0.878423\n",
      "[3000]\ttrain-auc:0.961192\tvalid-auc:0.879214\n",
      "[3100]\ttrain-auc:0.962005\tvalid-auc:0.880013\n",
      "[3200]\ttrain-auc:0.962767\tvalid-auc:0.880822\n",
      "[3300]\ttrain-auc:0.963528\tvalid-auc:0.881517\n",
      "[3400]\ttrain-auc:0.964276\tvalid-auc:0.882164\n",
      "[3500]\ttrain-auc:0.964955\tvalid-auc:0.882797\n",
      "[3600]\ttrain-auc:0.965579\tvalid-auc:0.88334\n",
      "[3700]\ttrain-auc:0.966172\tvalid-auc:0.883895\n",
      "[3800]\ttrain-auc:0.966793\tvalid-auc:0.884437\n",
      "[3900]\ttrain-auc:0.96739\tvalid-auc:0.884921\n",
      "[4000]\ttrain-auc:0.967919\tvalid-auc:0.885426\n",
      "[4100]\ttrain-auc:0.968455\tvalid-auc:0.885954\n",
      "[4200]\ttrain-auc:0.968961\tvalid-auc:0.886406\n",
      "[4300]\ttrain-auc:0.969458\tvalid-auc:0.886816\n",
      "[4400]\ttrain-auc:0.969973\tvalid-auc:0.887165\n",
      "[4500]\ttrain-auc:0.970441\tvalid-auc:0.887532\n",
      "[4600]\ttrain-auc:0.970892\tvalid-auc:0.88791\n",
      "[4700]\ttrain-auc:0.971303\tvalid-auc:0.888223\n",
      "[4800]\ttrain-auc:0.971714\tvalid-auc:0.888502\n",
      "[4900]\ttrain-auc:0.972128\tvalid-auc:0.88881\n",
      "[5000]\ttrain-auc:0.972547\tvalid-auc:0.889151\n",
      "[5100]\ttrain-auc:0.972896\tvalid-auc:0.88943\n",
      "[5200]\ttrain-auc:0.973251\tvalid-auc:0.889726\n",
      "[5300]\ttrain-auc:0.973608\tvalid-auc:0.890013\n",
      "[5400]\ttrain-auc:0.973949\tvalid-auc:0.890296\n",
      "[5500]\ttrain-auc:0.974275\tvalid-auc:0.890536\n",
      "[5600]\ttrain-auc:0.97463\tvalid-auc:0.890754\n",
      "[5700]\ttrain-auc:0.974958\tvalid-auc:0.890983\n",
      "[5800]\ttrain-auc:0.975281\tvalid-auc:0.891184\n",
      "[5900]\ttrain-auc:0.975579\tvalid-auc:0.891413\n",
      "[6000]\ttrain-auc:0.975859\tvalid-auc:0.891612\n",
      "[6100]\ttrain-auc:0.976132\tvalid-auc:0.891761\n",
      "[6200]\ttrain-auc:0.976413\tvalid-auc:0.891949\n",
      "[6300]\ttrain-auc:0.976698\tvalid-auc:0.892126\n",
      "[6400]\ttrain-auc:0.976969\tvalid-auc:0.892274\n",
      "[6500]\ttrain-auc:0.977242\tvalid-auc:0.892484\n",
      "[6600]\ttrain-auc:0.9775\tvalid-auc:0.89269\n",
      "[6700]\ttrain-auc:0.977734\tvalid-auc:0.892836\n",
      "[6800]\ttrain-auc:0.977973\tvalid-auc:0.892969\n",
      "[6900]\ttrain-auc:0.978213\tvalid-auc:0.893044\n",
      "[7000]\ttrain-auc:0.978441\tvalid-auc:0.893174\n",
      "[7100]\ttrain-auc:0.978673\tvalid-auc:0.89329\n",
      "[7200]\ttrain-auc:0.978888\tvalid-auc:0.893385\n",
      "[7300]\ttrain-auc:0.979123\tvalid-auc:0.893486\n",
      "[7400]\ttrain-auc:0.979353\tvalid-auc:0.893614\n",
      "[7500]\ttrain-auc:0.979557\tvalid-auc:0.893685\n",
      "[7600]\ttrain-auc:0.979777\tvalid-auc:0.893801\n",
      "[7700]\ttrain-auc:0.979993\tvalid-auc:0.893886\n",
      "[7800]\ttrain-auc:0.980181\tvalid-auc:0.894004\n",
      "[7900]\ttrain-auc:0.98038\tvalid-auc:0.894107\n",
      "[8000]\ttrain-auc:0.980585\tvalid-auc:0.894178\n",
      "[8100]\ttrain-auc:0.980773\tvalid-auc:0.894282\n",
      "[8200]\ttrain-auc:0.98096\tvalid-auc:0.894363\n",
      "[8300]\ttrain-auc:0.981147\tvalid-auc:0.894472\n",
      "[8400]\ttrain-auc:0.981338\tvalid-auc:0.894566\n",
      "[8500]\ttrain-auc:0.981517\tvalid-auc:0.89463\n",
      "[8600]\ttrain-auc:0.981699\tvalid-auc:0.8947\n",
      "[8700]\ttrain-auc:0.981887\tvalid-auc:0.894777\n",
      "[8800]\ttrain-auc:0.98206\tvalid-auc:0.894826\n",
      "[8900]\ttrain-auc:0.982241\tvalid-auc:0.894914\n",
      "[9000]\ttrain-auc:0.982412\tvalid-auc:0.89498\n",
      "[9100]\ttrain-auc:0.982576\tvalid-auc:0.895066\n",
      "[9200]\ttrain-auc:0.982753\tvalid-auc:0.895142\n",
      "[9300]\ttrain-auc:0.982926\tvalid-auc:0.895169\n",
      "[9400]\ttrain-auc:0.98309\tvalid-auc:0.895209\n",
      "[9500]\ttrain-auc:0.983256\tvalid-auc:0.89527\n",
      "[9600]\ttrain-auc:0.983413\tvalid-auc:0.895301\n",
      "[9700]\ttrain-auc:0.98357\tvalid-auc:0.895328\n",
      "[9800]\ttrain-auc:0.983725\tvalid-auc:0.895317\n",
      "[9900]\ttrain-auc:0.983881\tvalid-auc:0.895363\n",
      "[10000]\ttrain-auc:0.984041\tvalid-auc:0.895414\n",
      "[10100]\ttrain-auc:0.984188\tvalid-auc:0.895469\n",
      "[10200]\ttrain-auc:0.984335\tvalid-auc:0.895485\n",
      "[10300]\ttrain-auc:0.984484\tvalid-auc:0.895515\n",
      "[10400]\ttrain-auc:0.984633\tvalid-auc:0.895539\n",
      "[10500]\ttrain-auc:0.984778\tvalid-auc:0.895586\n",
      "[10600]\ttrain-auc:0.984929\tvalid-auc:0.895631\n",
      "[10700]\ttrain-auc:0.985077\tvalid-auc:0.895623\n",
      "[10800]\ttrain-auc:0.985221\tvalid-auc:0.89564\n",
      "[10900]\ttrain-auc:0.985368\tvalid-auc:0.895674\n",
      "[11000]\ttrain-auc:0.985511\tvalid-auc:0.895695\n",
      "[11100]\ttrain-auc:0.985647\tvalid-auc:0.895731\n",
      "[11200]\ttrain-auc:0.985786\tvalid-auc:0.895773\n",
      "[11300]\ttrain-auc:0.985926\tvalid-auc:0.895773\n",
      "[11400]\ttrain-auc:0.986064\tvalid-auc:0.895808\n",
      "[11500]\ttrain-auc:0.986201\tvalid-auc:0.895808\n",
      "[11600]\ttrain-auc:0.98633\tvalid-auc:0.895831\n",
      "[11700]\ttrain-auc:0.986454\tvalid-auc:0.895835\n",
      "[11800]\ttrain-auc:0.986585\tvalid-auc:0.895816\n",
      "[11900]\ttrain-auc:0.986716\tvalid-auc:0.895849\n",
      "[12000]\ttrain-auc:0.986843\tvalid-auc:0.895864\n",
      "[12100]\ttrain-auc:0.986976\tvalid-auc:0.895902\n",
      "[12200]\ttrain-auc:0.987104\tvalid-auc:0.8959\n",
      "[12300]\ttrain-auc:0.987231\tvalid-auc:0.895905\n",
      "[12400]\ttrain-auc:0.987355\tvalid-auc:0.895916\n",
      "[12500]\ttrain-auc:0.987481\tvalid-auc:0.895916\n",
      "[12600]\ttrain-auc:0.987601\tvalid-auc:0.895922\n",
      "[12700]\ttrain-auc:0.987727\tvalid-auc:0.895921\n",
      "[12800]\ttrain-auc:0.987854\tvalid-auc:0.895917\n",
      "[12900]\ttrain-auc:0.987985\tvalid-auc:0.895925\n",
      "Stopping. Best iteration:\n",
      "[12622]\ttrain-auc:0.987629\tvalid-auc:0.895935\n",
      "\n",
      "[Fold 2/5 Prediciton:]\n",
      "[Fold 3/5]\n",
      "[0]\ttrain-auc:0.636285\tvalid-auc:0.631592\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 300 rounds.\n",
      "[100]\ttrain-auc:0.814889\tvalid-auc:0.725679\n",
      "[200]\ttrain-auc:0.832816\tvalid-auc:0.741482\n",
      "[300]\ttrain-auc:0.858398\tvalid-auc:0.766366\n",
      "[400]\ttrain-auc:0.876114\tvalid-auc:0.786196\n",
      "[500]\ttrain-auc:0.888433\tvalid-auc:0.800671\n",
      "[600]\ttrain-auc:0.898153\tvalid-auc:0.812136\n",
      "[700]\ttrain-auc:0.905916\tvalid-auc:0.821688\n",
      "[800]\ttrain-auc:0.912654\tvalid-auc:0.829805\n",
      "[900]\ttrain-auc:0.918389\tvalid-auc:0.836644\n",
      "[1000]\ttrain-auc:0.922932\tvalid-auc:0.84198\n",
      "[1100]\ttrain-auc:0.926848\tvalid-auc:0.846488\n",
      "[1200]\ttrain-auc:0.930341\tvalid-auc:0.850372\n",
      "[1300]\ttrain-auc:0.933547\tvalid-auc:0.85397\n",
      "[1400]\ttrain-auc:0.936484\tvalid-auc:0.857245\n",
      "[1500]\ttrain-auc:0.93914\tvalid-auc:0.859999\n",
      "[1600]\ttrain-auc:0.941529\tvalid-auc:0.862528\n",
      "[1700]\ttrain-auc:0.943651\tvalid-auc:0.864745\n",
      "[1800]\ttrain-auc:0.945598\tvalid-auc:0.867084\n",
      "[1900]\ttrain-auc:0.947445\tvalid-auc:0.869027\n",
      "[2000]\ttrain-auc:0.949074\tvalid-auc:0.870854\n",
      "[2100]\ttrain-auc:0.950641\tvalid-auc:0.87251\n",
      "[2200]\ttrain-auc:0.952107\tvalid-auc:0.874091\n",
      "[2300]\ttrain-auc:0.953406\tvalid-auc:0.875608\n",
      "[2400]\ttrain-auc:0.954672\tvalid-auc:0.876934\n",
      "[2500]\ttrain-auc:0.955871\tvalid-auc:0.878166\n",
      "[2600]\ttrain-auc:0.956888\tvalid-auc:0.879304\n",
      "[2700]\ttrain-auc:0.957938\tvalid-auc:0.880313\n",
      "[2800]\ttrain-auc:0.958883\tvalid-auc:0.881368\n",
      "[2900]\ttrain-auc:0.959822\tvalid-auc:0.882325\n",
      "[3000]\ttrain-auc:0.960707\tvalid-auc:0.883258\n",
      "[3100]\ttrain-auc:0.961496\tvalid-auc:0.884101\n",
      "[3200]\ttrain-auc:0.962281\tvalid-auc:0.884853\n",
      "[3300]\ttrain-auc:0.963041\tvalid-auc:0.885743\n",
      "[3400]\ttrain-auc:0.963752\tvalid-auc:0.886439\n",
      "[3500]\ttrain-auc:0.964439\tvalid-auc:0.887062\n",
      "[3600]\ttrain-auc:0.965095\tvalid-auc:0.887635\n",
      "[3700]\ttrain-auc:0.965729\tvalid-auc:0.888261\n",
      "[3800]\ttrain-auc:0.966316\tvalid-auc:0.888845\n",
      "[3900]\ttrain-auc:0.966876\tvalid-auc:0.889333\n",
      "[4000]\ttrain-auc:0.967446\tvalid-auc:0.889846\n",
      "[4100]\ttrain-auc:0.967987\tvalid-auc:0.890334\n",
      "[4200]\ttrain-auc:0.968488\tvalid-auc:0.890754\n",
      "[4300]\ttrain-auc:0.96898\tvalid-auc:0.891166\n",
      "[4400]\ttrain-auc:0.969478\tvalid-auc:0.89156\n",
      "[4500]\ttrain-auc:0.969947\tvalid-auc:0.892029\n",
      "[4600]\ttrain-auc:0.970385\tvalid-auc:0.892391\n",
      "[4700]\ttrain-auc:0.970817\tvalid-auc:0.892726\n",
      "[4800]\ttrain-auc:0.971246\tvalid-auc:0.893045\n",
      "[4900]\ttrain-auc:0.971663\tvalid-auc:0.893362\n",
      "[5000]\ttrain-auc:0.972045\tvalid-auc:0.893718\n",
      "[5100]\ttrain-auc:0.972448\tvalid-auc:0.894031\n",
      "[5200]\ttrain-auc:0.972812\tvalid-auc:0.894307\n",
      "[5300]\ttrain-auc:0.973159\tvalid-auc:0.894563\n",
      "[5400]\ttrain-auc:0.973511\tvalid-auc:0.894797\n",
      "[5500]\ttrain-auc:0.973834\tvalid-auc:0.895031\n",
      "[5600]\ttrain-auc:0.974165\tvalid-auc:0.8953\n",
      "[5700]\ttrain-auc:0.974452\tvalid-auc:0.895494\n",
      "[5800]\ttrain-auc:0.974748\tvalid-auc:0.895689\n",
      "[5900]\ttrain-auc:0.975061\tvalid-auc:0.895907\n",
      "[6000]\ttrain-auc:0.975359\tvalid-auc:0.896124\n",
      "[6100]\ttrain-auc:0.975655\tvalid-auc:0.896324\n",
      "[6200]\ttrain-auc:0.975939\tvalid-auc:0.896501\n",
      "[6300]\ttrain-auc:0.976228\tvalid-auc:0.896686\n",
      "[6400]\ttrain-auc:0.976512\tvalid-auc:0.896886\n",
      "[6500]\ttrain-auc:0.976766\tvalid-auc:0.897077\n",
      "[6600]\ttrain-auc:0.977018\tvalid-auc:0.897232\n",
      "[6700]\ttrain-auc:0.97727\tvalid-auc:0.897353\n",
      "[6800]\ttrain-auc:0.977531\tvalid-auc:0.897495\n",
      "[6900]\ttrain-auc:0.977774\tvalid-auc:0.897625\n",
      "[7000]\ttrain-auc:0.978011\tvalid-auc:0.897786\n",
      "[7100]\ttrain-auc:0.978241\tvalid-auc:0.897909\n",
      "[7200]\ttrain-auc:0.978468\tvalid-auc:0.89802\n",
      "[7300]\ttrain-auc:0.978686\tvalid-auc:0.898163\n",
      "[7400]\ttrain-auc:0.978918\tvalid-auc:0.8983\n",
      "[7500]\ttrain-auc:0.979134\tvalid-auc:0.898397\n",
      "[7600]\ttrain-auc:0.979341\tvalid-auc:0.898486\n",
      "[7700]\ttrain-auc:0.979562\tvalid-auc:0.898599\n",
      "[7800]\ttrain-auc:0.979755\tvalid-auc:0.898729\n",
      "[7900]\ttrain-auc:0.979971\tvalid-auc:0.898839\n",
      "[8000]\ttrain-auc:0.980175\tvalid-auc:0.898906\n",
      "[8100]\ttrain-auc:0.980368\tvalid-auc:0.898954\n",
      "[8200]\ttrain-auc:0.980566\tvalid-auc:0.899042\n",
      "[8300]\ttrain-auc:0.980764\tvalid-auc:0.899138\n",
      "[8400]\ttrain-auc:0.980957\tvalid-auc:0.899216\n",
      "[8500]\ttrain-auc:0.981143\tvalid-auc:0.899305\n",
      "[8600]\ttrain-auc:0.98133\tvalid-auc:0.899397\n",
      "[8700]\ttrain-auc:0.981514\tvalid-auc:0.899478\n",
      "[8800]\ttrain-auc:0.981691\tvalid-auc:0.899579\n",
      "[8900]\ttrain-auc:0.981863\tvalid-auc:0.899627\n",
      "[9000]\ttrain-auc:0.982034\tvalid-auc:0.899717\n",
      "[9100]\ttrain-auc:0.982214\tvalid-auc:0.899749\n",
      "[9200]\ttrain-auc:0.98238\tvalid-auc:0.899788\n",
      "[9300]\ttrain-auc:0.982552\tvalid-auc:0.899867\n",
      "[9400]\ttrain-auc:0.98272\tvalid-auc:0.899933\n",
      "[9500]\ttrain-auc:0.982883\tvalid-auc:0.899957\n",
      "[9600]\ttrain-auc:0.983043\tvalid-auc:0.900003\n",
      "[9700]\ttrain-auc:0.983204\tvalid-auc:0.900039\n",
      "[9800]\ttrain-auc:0.983359\tvalid-auc:0.900086\n",
      "[9900]\ttrain-auc:0.98352\tvalid-auc:0.900118\n",
      "[10000]\ttrain-auc:0.983678\tvalid-auc:0.900155\n",
      "[10100]\ttrain-auc:0.98383\tvalid-auc:0.900182\n",
      "[10200]\ttrain-auc:0.983983\tvalid-auc:0.900256\n",
      "[10300]\ttrain-auc:0.98413\tvalid-auc:0.900279\n",
      "[10400]\ttrain-auc:0.984284\tvalid-auc:0.900285\n",
      "[10500]\ttrain-auc:0.984443\tvalid-auc:0.900291\n",
      "[10600]\ttrain-auc:0.984581\tvalid-auc:0.900305\n",
      "[10700]\ttrain-auc:0.984728\tvalid-auc:0.900308\n",
      "[10800]\ttrain-auc:0.984877\tvalid-auc:0.900329\n",
      "[10900]\ttrain-auc:0.985021\tvalid-auc:0.900369\n",
      "[11000]\ttrain-auc:0.985162\tvalid-auc:0.900403\n",
      "[11100]\ttrain-auc:0.985299\tvalid-auc:0.900388\n",
      "[11200]\ttrain-auc:0.985439\tvalid-auc:0.900386\n",
      "[11300]\ttrain-auc:0.985583\tvalid-auc:0.900397\n",
      "[11400]\ttrain-auc:0.985718\tvalid-auc:0.900445\n",
      "[11500]\ttrain-auc:0.985856\tvalid-auc:0.900449\n",
      "[11600]\ttrain-auc:0.985985\tvalid-auc:0.900461\n",
      "[11700]\ttrain-auc:0.986123\tvalid-auc:0.900499\n",
      "[11800]\ttrain-auc:0.986261\tvalid-auc:0.900487\n",
      "[11900]\ttrain-auc:0.986398\tvalid-auc:0.900498\n",
      "[12000]\ttrain-auc:0.986535\tvalid-auc:0.900503\n",
      "[12100]\ttrain-auc:0.986662\tvalid-auc:0.900515\n",
      "[12200]\ttrain-auc:0.986792\tvalid-auc:0.900529\n",
      "[12300]\ttrain-auc:0.986917\tvalid-auc:0.900526\n",
      "[12400]\ttrain-auc:0.987044\tvalid-auc:0.900533\n",
      "[12500]\ttrain-auc:0.987166\tvalid-auc:0.900549\n",
      "[12600]\ttrain-auc:0.987289\tvalid-auc:0.900552\n",
      "[12700]\ttrain-auc:0.987418\tvalid-auc:0.900567\n",
      "[12800]\ttrain-auc:0.987537\tvalid-auc:0.900549\n",
      "[12900]\ttrain-auc:0.987661\tvalid-auc:0.900537\n",
      "[13000]\ttrain-auc:0.987778\tvalid-auc:0.900545\n",
      "Stopping. Best iteration:\n",
      "[12720]\ttrain-auc:0.987442\tvalid-auc:0.900579\n",
      "\n",
      "[Fold 3/5 Prediciton:]\n",
      "[Fold 4/5]\n",
      "[0]\ttrain-auc:0.602319\tvalid-auc:0.588452\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 300 rounds.\n",
      "[100]\ttrain-auc:0.811763\tvalid-auc:0.727947\n",
      "[200]\ttrain-auc:0.837408\tvalid-auc:0.748588\n",
      "[300]\ttrain-auc:0.859308\tvalid-auc:0.77178\n",
      "[400]\ttrain-auc:0.877324\tvalid-auc:0.790297\n",
      "[500]\ttrain-auc:0.890221\tvalid-auc:0.804331\n",
      "[600]\ttrain-auc:0.899504\tvalid-auc:0.814325\n",
      "[700]\ttrain-auc:0.906911\tvalid-auc:0.822828\n",
      "[800]\ttrain-auc:0.91323\tvalid-auc:0.829859\n",
      "[900]\ttrain-auc:0.918997\tvalid-auc:0.836418\n",
      "[1000]\ttrain-auc:0.923486\tvalid-auc:0.841385\n",
      "[1100]\ttrain-auc:0.927553\tvalid-auc:0.846107\n",
      "[1200]\ttrain-auc:0.931077\tvalid-auc:0.85006\n",
      "[1300]\ttrain-auc:0.934157\tvalid-auc:0.853694\n",
      "[1400]\ttrain-auc:0.93697\tvalid-auc:0.85689\n",
      "[1500]\ttrain-auc:0.939484\tvalid-auc:0.859737\n",
      "[1600]\ttrain-auc:0.941811\tvalid-auc:0.862316\n",
      "[1700]\ttrain-auc:0.943954\tvalid-auc:0.864769\n",
      "[1800]\ttrain-auc:0.945888\tvalid-auc:0.866864\n",
      "[1900]\ttrain-auc:0.9476\tvalid-auc:0.868837\n",
      "[2000]\ttrain-auc:0.949235\tvalid-auc:0.870606\n",
      "[2100]\ttrain-auc:0.950775\tvalid-auc:0.872273\n",
      "[2200]\ttrain-auc:0.952206\tvalid-auc:0.873719\n",
      "[2300]\ttrain-auc:0.953677\tvalid-auc:0.875163\n",
      "[2400]\ttrain-auc:0.954897\tvalid-auc:0.876361\n",
      "[2500]\ttrain-auc:0.956087\tvalid-auc:0.877704\n",
      "[2600]\ttrain-auc:0.957264\tvalid-auc:0.878842\n",
      "[2700]\ttrain-auc:0.95823\tvalid-auc:0.879777\n",
      "[2800]\ttrain-auc:0.959165\tvalid-auc:0.880635\n",
      "[2900]\ttrain-auc:0.960064\tvalid-auc:0.8816\n",
      "[3000]\ttrain-auc:0.960921\tvalid-auc:0.88247\n",
      "[3100]\ttrain-auc:0.96177\tvalid-auc:0.883344\n",
      "[3200]\ttrain-auc:0.962521\tvalid-auc:0.884106\n",
      "[3300]\ttrain-auc:0.963288\tvalid-auc:0.884859\n",
      "[3400]\ttrain-auc:0.964025\tvalid-auc:0.885506\n",
      "[3500]\ttrain-auc:0.964713\tvalid-auc:0.886181\n",
      "[3600]\ttrain-auc:0.965334\tvalid-auc:0.886835\n",
      "[3700]\ttrain-auc:0.965961\tvalid-auc:0.887397\n",
      "[3800]\ttrain-auc:0.966555\tvalid-auc:0.887941\n",
      "[3900]\ttrain-auc:0.967121\tvalid-auc:0.888429\n",
      "[4000]\ttrain-auc:0.967686\tvalid-auc:0.888935\n",
      "[4100]\ttrain-auc:0.968222\tvalid-auc:0.889409\n",
      "[4200]\ttrain-auc:0.968722\tvalid-auc:0.889843\n",
      "[4300]\ttrain-auc:0.969224\tvalid-auc:0.890275\n",
      "[4400]\ttrain-auc:0.969707\tvalid-auc:0.890687\n",
      "[4500]\ttrain-auc:0.970139\tvalid-auc:0.891043\n",
      "[4600]\ttrain-auc:0.970588\tvalid-auc:0.891422\n",
      "[4700]\ttrain-auc:0.971014\tvalid-auc:0.891753\n",
      "[4800]\ttrain-auc:0.971433\tvalid-auc:0.892093\n",
      "[4900]\ttrain-auc:0.971831\tvalid-auc:0.892419\n",
      "[5000]\ttrain-auc:0.972218\tvalid-auc:0.892702\n",
      "[5100]\ttrain-auc:0.972596\tvalid-auc:0.893004\n",
      "[5200]\ttrain-auc:0.972962\tvalid-auc:0.893297\n",
      "[5300]\ttrain-auc:0.973333\tvalid-auc:0.893571\n",
      "[5400]\ttrain-auc:0.973669\tvalid-auc:0.893841\n",
      "[5500]\ttrain-auc:0.974018\tvalid-auc:0.894084\n",
      "[5600]\ttrain-auc:0.974351\tvalid-auc:0.894353\n",
      "[5700]\ttrain-auc:0.974666\tvalid-auc:0.894605\n",
      "[5800]\ttrain-auc:0.974978\tvalid-auc:0.894786\n",
      "[5900]\ttrain-auc:0.975267\tvalid-auc:0.894975\n",
      "[6000]\ttrain-auc:0.975556\tvalid-auc:0.895187\n",
      "[6100]\ttrain-auc:0.975859\tvalid-auc:0.895419\n",
      "[6200]\ttrain-auc:0.976137\tvalid-auc:0.895613\n",
      "[6300]\ttrain-auc:0.976425\tvalid-auc:0.895802\n",
      "[6400]\ttrain-auc:0.97669\tvalid-auc:0.895967\n",
      "[6500]\ttrain-auc:0.976976\tvalid-auc:0.896118\n",
      "[6600]\ttrain-auc:0.977243\tvalid-auc:0.896272\n",
      "[6700]\ttrain-auc:0.977506\tvalid-auc:0.896412\n",
      "[6800]\ttrain-auc:0.977748\tvalid-auc:0.896523\n",
      "[6900]\ttrain-auc:0.977982\tvalid-auc:0.896707\n",
      "[7000]\ttrain-auc:0.97821\tvalid-auc:0.896847\n",
      "[7100]\ttrain-auc:0.97845\tvalid-auc:0.896994\n",
      "[7200]\ttrain-auc:0.978667\tvalid-auc:0.897117\n",
      "[7300]\ttrain-auc:0.978883\tvalid-auc:0.89725\n",
      "[7400]\ttrain-auc:0.979106\tvalid-auc:0.897341\n",
      "[7500]\ttrain-auc:0.979319\tvalid-auc:0.897455\n",
      "[7600]\ttrain-auc:0.979538\tvalid-auc:0.897593\n",
      "[7700]\ttrain-auc:0.97975\tvalid-auc:0.897704\n",
      "[7800]\ttrain-auc:0.979959\tvalid-auc:0.897842\n",
      "[7900]\ttrain-auc:0.980148\tvalid-auc:0.897937\n",
      "[8000]\ttrain-auc:0.980352\tvalid-auc:0.89804\n",
      "[8100]\ttrain-auc:0.980549\tvalid-auc:0.898152\n",
      "[8200]\ttrain-auc:0.980743\tvalid-auc:0.8982\n",
      "[8300]\ttrain-auc:0.980925\tvalid-auc:0.898291\n",
      "[8400]\ttrain-auc:0.981117\tvalid-auc:0.898388\n",
      "[8500]\ttrain-auc:0.981318\tvalid-auc:0.898449\n",
      "[8600]\ttrain-auc:0.981499\tvalid-auc:0.89853\n",
      "[8700]\ttrain-auc:0.981678\tvalid-auc:0.898592\n",
      "[8800]\ttrain-auc:0.98186\tvalid-auc:0.898659\n",
      "[8900]\ttrain-auc:0.982033\tvalid-auc:0.898725\n",
      "[9000]\ttrain-auc:0.982196\tvalid-auc:0.898786\n",
      "[9100]\ttrain-auc:0.982365\tvalid-auc:0.898841\n",
      "[9200]\ttrain-auc:0.982521\tvalid-auc:0.898888\n",
      "[9300]\ttrain-auc:0.982675\tvalid-auc:0.898928\n",
      "[9400]\ttrain-auc:0.982844\tvalid-auc:0.898968\n",
      "[9500]\ttrain-auc:0.983012\tvalid-auc:0.89901\n",
      "[9600]\ttrain-auc:0.983176\tvalid-auc:0.899079\n",
      "[9700]\ttrain-auc:0.98333\tvalid-auc:0.899114\n",
      "[9800]\ttrain-auc:0.983489\tvalid-auc:0.899164\n",
      "[9900]\ttrain-auc:0.983651\tvalid-auc:0.899197\n",
      "[10000]\ttrain-auc:0.9838\tvalid-auc:0.899227\n",
      "[10100]\ttrain-auc:0.983945\tvalid-auc:0.899266\n",
      "[10200]\ttrain-auc:0.984098\tvalid-auc:0.899301\n",
      "[10300]\ttrain-auc:0.984246\tvalid-auc:0.899341\n",
      "[10400]\ttrain-auc:0.984389\tvalid-auc:0.899384\n",
      "[10500]\ttrain-auc:0.984538\tvalid-auc:0.899424\n",
      "[10600]\ttrain-auc:0.984687\tvalid-auc:0.899457\n",
      "[10700]\ttrain-auc:0.98483\tvalid-auc:0.899498\n",
      "[10800]\ttrain-auc:0.984972\tvalid-auc:0.899516\n",
      "[10900]\ttrain-auc:0.985109\tvalid-auc:0.899557\n",
      "[11000]\ttrain-auc:0.985249\tvalid-auc:0.899596\n",
      "[11100]\ttrain-auc:0.985389\tvalid-auc:0.899605\n",
      "[11200]\ttrain-auc:0.985522\tvalid-auc:0.899629\n",
      "[11300]\ttrain-auc:0.985664\tvalid-auc:0.899645\n",
      "[11400]\ttrain-auc:0.985807\tvalid-auc:0.899682\n",
      "[11500]\ttrain-auc:0.985941\tvalid-auc:0.899745\n",
      "[11600]\ttrain-auc:0.986074\tvalid-auc:0.89977\n",
      "[11700]\ttrain-auc:0.986207\tvalid-auc:0.899759\n",
      "[11800]\ttrain-auc:0.986344\tvalid-auc:0.899758\n",
      "[11900]\ttrain-auc:0.986473\tvalid-auc:0.89978\n",
      "[12000]\ttrain-auc:0.986603\tvalid-auc:0.899771\n",
      "[12100]\ttrain-auc:0.986734\tvalid-auc:0.899765\n",
      "[12200]\ttrain-auc:0.98686\tvalid-auc:0.899773\n",
      "[12300]\ttrain-auc:0.98699\tvalid-auc:0.89979\n",
      "[12400]\ttrain-auc:0.987127\tvalid-auc:0.899821\n",
      "[12500]\ttrain-auc:0.987252\tvalid-auc:0.89982\n",
      "[12600]\ttrain-auc:0.987384\tvalid-auc:0.89984\n",
      "[12700]\ttrain-auc:0.987512\tvalid-auc:0.899875\n",
      "[12800]\ttrain-auc:0.987639\tvalid-auc:0.899889\n",
      "[12900]\ttrain-auc:0.987765\tvalid-auc:0.899893\n",
      "[13000]\ttrain-auc:0.98789\tvalid-auc:0.899876\n",
      "Stopping. Best iteration:\n",
      "[12766]\ttrain-auc:0.987595\tvalid-auc:0.8999\n",
      "\n",
      "[Fold 4/5 Prediciton:]\n",
      "[Fold 5/5]\n",
      "[0]\ttrain-auc:0.614065\tvalid-auc:0.601639\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 300 rounds.\n",
      "[100]\ttrain-auc:0.808337\tvalid-auc:0.734195\n",
      "[200]\ttrain-auc:0.833827\tvalid-auc:0.755947\n",
      "[300]\ttrain-auc:0.856925\tvalid-auc:0.780274\n",
      "[400]\ttrain-auc:0.875299\tvalid-auc:0.799562\n",
      "[500]\ttrain-auc:0.888508\tvalid-auc:0.813838\n",
      "[600]\ttrain-auc:0.897519\tvalid-auc:0.82383\n",
      "[700]\ttrain-auc:0.905227\tvalid-auc:0.831628\n",
      "[800]\ttrain-auc:0.912326\tvalid-auc:0.838794\n",
      "[900]\ttrain-auc:0.917833\tvalid-auc:0.844671\n",
      "[1000]\ttrain-auc:0.922306\tvalid-auc:0.849551\n",
      "[1100]\ttrain-auc:0.926459\tvalid-auc:0.854017\n",
      "[1200]\ttrain-auc:0.930185\tvalid-auc:0.857828\n",
      "[1300]\ttrain-auc:0.933528\tvalid-auc:0.861079\n",
      "[1400]\ttrain-auc:0.936478\tvalid-auc:0.864051\n",
      "[1500]\ttrain-auc:0.939072\tvalid-auc:0.866565\n",
      "[1600]\ttrain-auc:0.94141\tvalid-auc:0.868859\n",
      "[1700]\ttrain-auc:0.943474\tvalid-auc:0.87109\n",
      "[1800]\ttrain-auc:0.945337\tvalid-auc:0.87306\n",
      "[1900]\ttrain-auc:0.947103\tvalid-auc:0.874773\n",
      "[2000]\ttrain-auc:0.94876\tvalid-auc:0.876403\n",
      "[2100]\ttrain-auc:0.950331\tvalid-auc:0.877963\n",
      "[2200]\ttrain-auc:0.951785\tvalid-auc:0.87935\n",
      "[2300]\ttrain-auc:0.95318\tvalid-auc:0.880571\n",
      "[2400]\ttrain-auc:0.954389\tvalid-auc:0.8816\n",
      "[2500]\ttrain-auc:0.955519\tvalid-auc:0.882572\n",
      "[2600]\ttrain-auc:0.956586\tvalid-auc:0.883491\n",
      "[2700]\ttrain-auc:0.957604\tvalid-auc:0.884455\n",
      "[2800]\ttrain-auc:0.958611\tvalid-auc:0.885339\n",
      "[2900]\ttrain-auc:0.959558\tvalid-auc:0.886192\n",
      "[3000]\ttrain-auc:0.960423\tvalid-auc:0.886977\n",
      "[3100]\ttrain-auc:0.961274\tvalid-auc:0.887719\n",
      "[3200]\ttrain-auc:0.96207\tvalid-auc:0.888428\n",
      "[3300]\ttrain-auc:0.96281\tvalid-auc:0.889023\n",
      "[3400]\ttrain-auc:0.963532\tvalid-auc:0.889629\n",
      "[3500]\ttrain-auc:0.964197\tvalid-auc:0.89025\n",
      "[3600]\ttrain-auc:0.964848\tvalid-auc:0.890759\n",
      "[3700]\ttrain-auc:0.965495\tvalid-auc:0.891307\n",
      "[3800]\ttrain-auc:0.966058\tvalid-auc:0.891848\n",
      "[3900]\ttrain-auc:0.966667\tvalid-auc:0.892368\n",
      "[4000]\ttrain-auc:0.967201\tvalid-auc:0.892902\n",
      "[4100]\ttrain-auc:0.967711\tvalid-auc:0.893351\n",
      "[4200]\ttrain-auc:0.968235\tvalid-auc:0.893789\n",
      "[4300]\ttrain-auc:0.968752\tvalid-auc:0.89418\n",
      "[4400]\ttrain-auc:0.969231\tvalid-auc:0.894561\n",
      "[4500]\ttrain-auc:0.969716\tvalid-auc:0.894956\n",
      "[4600]\ttrain-auc:0.970157\tvalid-auc:0.895272\n",
      "[4700]\ttrain-auc:0.970618\tvalid-auc:0.895627\n",
      "[4800]\ttrain-auc:0.971053\tvalid-auc:0.895922\n",
      "[4900]\ttrain-auc:0.971434\tvalid-auc:0.896256\n",
      "[5000]\ttrain-auc:0.971838\tvalid-auc:0.896571\n",
      "[5100]\ttrain-auc:0.972217\tvalid-auc:0.89682\n",
      "[5200]\ttrain-auc:0.972604\tvalid-auc:0.897084\n",
      "[5300]\ttrain-auc:0.972973\tvalid-auc:0.897338\n",
      "[5400]\ttrain-auc:0.973304\tvalid-auc:0.897613\n",
      "[5500]\ttrain-auc:0.973657\tvalid-auc:0.897809\n",
      "[5600]\ttrain-auc:0.973988\tvalid-auc:0.898045\n",
      "[5700]\ttrain-auc:0.974327\tvalid-auc:0.898227\n",
      "[5800]\ttrain-auc:0.974636\tvalid-auc:0.898428\n",
      "[5900]\ttrain-auc:0.974945\tvalid-auc:0.8986\n",
      "[6000]\ttrain-auc:0.975247\tvalid-auc:0.898767\n",
      "[6100]\ttrain-auc:0.975541\tvalid-auc:0.898946\n",
      "[6200]\ttrain-auc:0.975827\tvalid-auc:0.899101\n",
      "[6300]\ttrain-auc:0.976115\tvalid-auc:0.899232\n",
      "[6400]\ttrain-auc:0.97638\tvalid-auc:0.899371\n",
      "[6500]\ttrain-auc:0.976657\tvalid-auc:0.899515\n",
      "[6600]\ttrain-auc:0.976924\tvalid-auc:0.899631\n",
      "[6700]\ttrain-auc:0.977179\tvalid-auc:0.899784\n",
      "[6800]\ttrain-auc:0.977408\tvalid-auc:0.899886\n",
      "[6900]\ttrain-auc:0.977653\tvalid-auc:0.900019\n",
      "[7000]\ttrain-auc:0.977881\tvalid-auc:0.900143\n",
      "[7100]\ttrain-auc:0.978135\tvalid-auc:0.900272\n",
      "[7200]\ttrain-auc:0.978369\tvalid-auc:0.900369\n",
      "[7300]\ttrain-auc:0.978596\tvalid-auc:0.900435\n",
      "[7400]\ttrain-auc:0.978809\tvalid-auc:0.900516\n",
      "[7500]\ttrain-auc:0.979036\tvalid-auc:0.900635\n",
      "[7600]\ttrain-auc:0.979258\tvalid-auc:0.900702\n",
      "[7700]\ttrain-auc:0.979476\tvalid-auc:0.900814\n",
      "[7800]\ttrain-auc:0.979695\tvalid-auc:0.900877\n",
      "[7900]\ttrain-auc:0.979894\tvalid-auc:0.900971\n",
      "[8000]\ttrain-auc:0.9801\tvalid-auc:0.901023\n",
      "[8100]\ttrain-auc:0.980314\tvalid-auc:0.901084\n",
      "[8200]\ttrain-auc:0.980516\tvalid-auc:0.901165\n",
      "[8300]\ttrain-auc:0.980693\tvalid-auc:0.901205\n",
      "[8400]\ttrain-auc:0.980887\tvalid-auc:0.901261\n",
      "[8500]\ttrain-auc:0.981074\tvalid-auc:0.901327\n",
      "[8600]\ttrain-auc:0.981251\tvalid-auc:0.901382\n",
      "[8700]\ttrain-auc:0.981438\tvalid-auc:0.901443\n",
      "[8800]\ttrain-auc:0.981609\tvalid-auc:0.901478\n",
      "[8900]\ttrain-auc:0.981788\tvalid-auc:0.90152\n",
      "[9000]\ttrain-auc:0.981964\tvalid-auc:0.901551\n",
      "[9100]\ttrain-auc:0.982141\tvalid-auc:0.901591\n",
      "[9200]\ttrain-auc:0.982312\tvalid-auc:0.901618\n",
      "[9300]\ttrain-auc:0.982477\tvalid-auc:0.901682\n",
      "[9400]\ttrain-auc:0.982644\tvalid-auc:0.901735\n",
      "[9500]\ttrain-auc:0.982808\tvalid-auc:0.901729\n",
      "[9600]\ttrain-auc:0.982975\tvalid-auc:0.901757\n",
      "[9700]\ttrain-auc:0.983129\tvalid-auc:0.901791\n",
      "[9800]\ttrain-auc:0.983281\tvalid-auc:0.901838\n",
      "[9900]\ttrain-auc:0.983444\tvalid-auc:0.901865\n",
      "[10000]\ttrain-auc:0.983601\tvalid-auc:0.901905\n",
      "[10100]\ttrain-auc:0.98376\tvalid-auc:0.901931\n",
      "[10200]\ttrain-auc:0.98391\tvalid-auc:0.901962\n",
      "[10300]\ttrain-auc:0.984058\tvalid-auc:0.901988\n",
      "[10400]\ttrain-auc:0.98421\tvalid-auc:0.902028\n",
      "[10500]\ttrain-auc:0.984359\tvalid-auc:0.902043\n",
      "[10600]\ttrain-auc:0.984508\tvalid-auc:0.902077\n",
      "[10700]\ttrain-auc:0.984656\tvalid-auc:0.902081\n",
      "[10800]\ttrain-auc:0.98481\tvalid-auc:0.902085\n",
      "[10900]\ttrain-auc:0.98496\tvalid-auc:0.902083\n",
      "[11000]\ttrain-auc:0.985103\tvalid-auc:0.902114\n",
      "[11100]\ttrain-auc:0.985249\tvalid-auc:0.902125\n",
      "[11200]\ttrain-auc:0.985397\tvalid-auc:0.902124\n",
      "[11300]\ttrain-auc:0.985539\tvalid-auc:0.902141\n",
      "[11400]\ttrain-auc:0.985682\tvalid-auc:0.902133\n",
      "[11500]\ttrain-auc:0.985821\tvalid-auc:0.902143\n",
      "[11600]\ttrain-auc:0.985961\tvalid-auc:0.902155\n",
      "[11700]\ttrain-auc:0.986098\tvalid-auc:0.902174\n",
      "[11800]\ttrain-auc:0.986234\tvalid-auc:0.902175\n",
      "[11900]\ttrain-auc:0.986371\tvalid-auc:0.902166\n",
      "[12000]\ttrain-auc:0.986513\tvalid-auc:0.902204\n",
      "[12100]\ttrain-auc:0.98664\tvalid-auc:0.902217\n",
      "[12200]\ttrain-auc:0.98677\tvalid-auc:0.90223\n",
      "[12300]\ttrain-auc:0.986902\tvalid-auc:0.902236\n",
      "[12400]\ttrain-auc:0.987037\tvalid-auc:0.902217\n",
      "[12500]\ttrain-auc:0.987172\tvalid-auc:0.902213\n",
      "Stopping. Best iteration:\n",
      "[12281]\ttrain-auc:0.986877\tvalid-auc:0.902248\n",
      "\n",
      "[Fold 5/5 Prediciton:]\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(skf.split(train, y)):\n",
    "    print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "    \n",
    "    t = train.iloc[train_index]\n",
    "    t = augment(t)   \n",
    "    train_data = t.drop(['target','ID_code'], axis=1)\n",
    "    y_train = t.target.values\n",
    "    \n",
    "    \n",
    "    valid_data= train.iloc[test_index]\n",
    "    y_valid = valid_data.target.values\n",
    "    valid_data = valid_data.drop(['target','ID_code'], axis=1)\n",
    "   \n",
    "   \n",
    "    # Convert our data into XGBoost format\n",
    "    d_train = xgb.DMatrix(train_data, y_train)\n",
    "    d_valid = xgb.DMatrix(valid_data, y_valid)\n",
    "    d_test = xgb.DMatrix(X_test)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    mdl = xgb.train(params, d_train, 15000, watchlist, early_stopping_rounds=300, maximize=True, verbose_eval=100)\n",
    "\n",
    "    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n",
    "    # Predict on our test data\n",
    "    p_test = mdl.predict(d_test, ntree_limit=mdl.best_ntree_limit)\n",
    "    sub['target'] += p_test/kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('StratifiedKFoldaugFeatures.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.columns = [\"ID_code\",\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.0565045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.221241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.216036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.215526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.0177518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code     target\n",
       "0  test_0  0.0565045\n",
       "1  test_1   0.221241\n",
       "2  test_2   0.216036\n",
       "3  test_3   0.215526\n",
       "4  test_4  0.0177518"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"StratKFoldAugmentation.csv\", index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "2  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417  -6.5213   \n",
       "3  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706  -2.9275   \n",
       "4  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   3.9267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "2   8.2675  14.7222   0.3965  \n",
       "3  10.2922  17.9697  -8.9996  \n",
       "4   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import linear_model\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lm = linear_model.LogisticRegression(penalty=\"l2\", C = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier(missing=np.nan, max_depth=3, n_estimators=2000,\n",
    "                        min_child_weight = 3,\n",
    "                        learning_rate=0.02, subsample=0.7, colsample_bytree=0.7, random_state=6744, verbose = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_model = VotingClassifier(estimators=[('xgb1', model_xgb),\n",
    "                                    ('logistic_reg', model_lm)], voting='soft',weights=[8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_model_tr = unbooked_gam.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_probas = voting_model_tr.predict_proba(X_predictions)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code target\n",
       "0  test_0    NaN\n",
       "1  test_1    NaN\n",
       "2  test_2    NaN\n",
       "3  test_3    NaN\n",
       "4  test_4    NaN"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnId = 'ID_code'\n",
    "columnTarget = 'target'\n",
    "sub = pd.DataFrame(inputTest[columnId], columns=[columnId,columnTarget])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ca5f217952c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "sub.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('votingClass.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['target']=voting_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8963790671353871"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, voting_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0    var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
       "1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
       "2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.2537   \n",
       "3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.5660   \n",
       "4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.6048   \n",
       "\n",
       "    var_8   var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  2.1337  8.8100  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1 -4.4131  5.9739  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  1.5233  8.3442  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  3.3755  7.4578  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  2.9890  7.1437  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Collecting lightgbm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/b3/7b6aec53a8cd0a1378279d9f06e647298f0c66299bce0e4b2b919f6557f7/lightgbm-2.2.3-py2.py3-none-macosx_10_8_x86_64.macosx_10_9_x86_64.macosx_10_10_x86_64.macosx_10_11_x86_64.macosx_10_12_x86_64.macosx_10_13_x86_64.macosx_10_14_x86_64.whl (640kB)\n",
      "\u001b[K    100% |████████████████████████████████| 645kB 4.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in ./venv/lib/python2.7/site-packages (from lightgbm) (1.2.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python2.7/site-packages (from lightgbm) (1.16.2)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python2.7/site-packages (from lightgbm) (0.20.3)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.2.3\n"
     ]
    }
   ],
   "source": [
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jpoberhauser/Desktop/competitions/santander/venv/lib/python2.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"data/santander-customer-transaction-prediction/train.csv\").drop(\"ID_code\",axis=1)\n",
    "test=pd.read_csv(\"data/santander-customer-transaction-prediction/test.csv\").drop(\"ID_code\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0    var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
       "1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
       "2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.2537   \n",
       "3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.5660   \n",
       "4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.6048   \n",
       "\n",
       "    var_8   var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  2.1337  8.8100  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1 -4.4131  5.9739  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  1.5233  8.3442  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  3.3755  7.4578  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  2.9890  7.1437  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspiration from\n",
    "#https://www.kaggle.com/jiweiliu/lgb-2-leaves-augment\n",
    "def augment(train,num_n=1,num_p=3):\n",
    "    newtrain=[train]\n",
    "    \n",
    "    n=train[train.target==0]\n",
    "    for i in range(num_n):\n",
    "        newtrain.append(n.apply(lambda x:x.values.take(np.random.permutation(len(n)))))\n",
    "    \n",
    "    for i in range(num_p):\n",
    "        p=train[train.target>0]\n",
    "        newtrain.append(p.apply(lambda x:x.values.take(np.random.permutation(len(p)))))\n",
    "    return pd.concat(newtrain)\n",
    "#df=oversample(train,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "   \"objective\" : \"binary\",\n",
    "    \"metric\" : \"auc\",\n",
    "    \"boosting\": 'gbdt',\n",
    "    \"max_depth\" : -1,\n",
    "    \"num_leaves\" : 13,\n",
    "    \"learning_rate\" : 0.01,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"bagging_fraction\" : 0.4,\n",
    "    \"feature_fraction\" : 0.05,\n",
    "    \"min_data_in_leaf\": 80,\n",
    "    \"min_sum_heassian_in_leaf\": 10,\n",
    "    \"tree_learner\": \"serial\",\n",
    "    \"boost_from_average\": \"false\",\n",
    "    \"bagging_seed\" : 10,\n",
    "    \"verbosity\" : 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[500]\tvalid_0's auc: 0.872273\n",
      "[1000]\tvalid_0's auc: 0.879627\n",
      "[1500]\tvalid_0's auc: 0.88364\n",
      "[2000]\tvalid_0's auc: 0.887469\n",
      "[2500]\tvalid_0's auc: 0.8899\n",
      "[3000]\tvalid_0's auc: 0.892074\n",
      "[3500]\tvalid_0's auc: 0.893635\n",
      "[4000]\tvalid_0's auc: 0.894913\n",
      "[4500]\tvalid_0's auc: 0.895861\n",
      "[5000]\tvalid_0's auc: 0.896565\n",
      "[5500]\tvalid_0's auc: 0.897044\n",
      "[6000]\tvalid_0's auc: 0.897407\n",
      "[6500]\tvalid_0's auc: 0.897603\n",
      "[7000]\tvalid_0's auc: 0.897816\n",
      "[7500]\tvalid_0's auc: 0.898017\n",
      "[8000]\tvalid_0's auc: 0.898056\n",
      "[8500]\tvalid_0's auc: 0.898086\n",
      "[9000]\tvalid_0's auc: 0.898101\n",
      "[9500]\tvalid_0's auc: 0.898151\n",
      "[10000]\tvalid_0's auc: 0.898103\n",
      "[10500]\tvalid_0's auc: 0.898033\n",
      "[11000]\tvalid_0's auc: 0.897971\n",
      "[11500]\tvalid_0's auc: 0.897886\n",
      "[12000]\tvalid_0's auc: 0.897822\n",
      "Early stopping, best iteration is:\n",
      "[9413]\tvalid_0's auc: 0.898161\n",
      "2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[500]\tvalid_0's auc: 0.874705\n",
      "[1000]\tvalid_0's auc: 0.882856\n",
      "[1500]\tvalid_0's auc: 0.887624\n",
      "[2000]\tvalid_0's auc: 0.890595\n",
      "[2500]\tvalid_0's auc: 0.893051\n",
      "[3000]\tvalid_0's auc: 0.894755\n",
      "[3500]\tvalid_0's auc: 0.896075\n",
      "[4000]\tvalid_0's auc: 0.897081\n",
      "[4500]\tvalid_0's auc: 0.897912\n",
      "[5000]\tvalid_0's auc: 0.898499\n",
      "[5500]\tvalid_0's auc: 0.898926\n",
      "[6000]\tvalid_0's auc: 0.899263\n",
      "[6500]\tvalid_0's auc: 0.899454\n",
      "[7000]\tvalid_0's auc: 0.899653\n",
      "[7500]\tvalid_0's auc: 0.899845\n",
      "[8000]\tvalid_0's auc: 0.899949\n",
      "[8500]\tvalid_0's auc: 0.900012\n",
      "[9000]\tvalid_0's auc: 0.899955\n",
      "[9500]\tvalid_0's auc: 0.899956\n",
      "[10000]\tvalid_0's auc: 0.899916\n",
      "[10500]\tvalid_0's auc: 0.899889\n",
      "[11000]\tvalid_0's auc: 0.899823\n",
      "Early stopping, best iteration is:\n",
      "[8336]\tvalid_0's auc: 0.90003\n",
      "3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[500]\tvalid_0's auc: 0.873275\n",
      "[1000]\tvalid_0's auc: 0.880744\n",
      "[1500]\tvalid_0's auc: 0.885188\n",
      "[2000]\tvalid_0's auc: 0.888662\n",
      "[2500]\tvalid_0's auc: 0.891173\n",
      "[3000]\tvalid_0's auc: 0.893318\n",
      "[3500]\tvalid_0's auc: 0.894886\n",
      "[4000]\tvalid_0's auc: 0.89614\n",
      "[4500]\tvalid_0's auc: 0.897019\n",
      "[5000]\tvalid_0's auc: 0.897754\n",
      "[5500]\tvalid_0's auc: 0.89819\n",
      "[6000]\tvalid_0's auc: 0.898532\n",
      "[6500]\tvalid_0's auc: 0.898849\n",
      "[7000]\tvalid_0's auc: 0.899072\n",
      "[7500]\tvalid_0's auc: 0.899202\n",
      "[8000]\tvalid_0's auc: 0.899252\n",
      "[8500]\tvalid_0's auc: 0.899275\n",
      "[9000]\tvalid_0's auc: 0.899311\n",
      "[9500]\tvalid_0's auc: 0.899368\n",
      "[10000]\tvalid_0's auc: 0.899343\n",
      "[10500]\tvalid_0's auc: 0.899325\n",
      "[11000]\tvalid_0's auc: 0.899241\n",
      "[11500]\tvalid_0's auc: 0.899239\n",
      "[12000]\tvalid_0's auc: 0.899182\n",
      "Early stopping, best iteration is:\n",
      "[9490]\tvalid_0's auc: 0.89937\n",
      "4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[500]\tvalid_0's auc: 0.872927\n",
      "[1000]\tvalid_0's auc: 0.881528\n",
      "[1500]\tvalid_0's auc: 0.886001\n",
      "[2000]\tvalid_0's auc: 0.889644\n",
      "[2500]\tvalid_0's auc: 0.892106\n",
      "[3000]\tvalid_0's auc: 0.894104\n",
      "[3500]\tvalid_0's auc: 0.895592\n",
      "[4000]\tvalid_0's auc: 0.89674\n",
      "[4500]\tvalid_0's auc: 0.897615\n",
      "[5000]\tvalid_0's auc: 0.898354\n",
      "[5500]\tvalid_0's auc: 0.8989\n",
      "[6000]\tvalid_0's auc: 0.899309\n",
      "[6500]\tvalid_0's auc: 0.899573\n",
      "[7000]\tvalid_0's auc: 0.899706\n",
      "[7500]\tvalid_0's auc: 0.899879\n",
      "[8000]\tvalid_0's auc: 0.89994\n",
      "[8500]\tvalid_0's auc: 0.899958\n",
      "[9000]\tvalid_0's auc: 0.89995\n",
      "[9500]\tvalid_0's auc: 0.899953\n",
      "[10000]\tvalid_0's auc: 0.899922\n",
      "[10500]\tvalid_0's auc: 0.899911\n",
      "[11000]\tvalid_0's auc: 0.899877\n",
      "[11500]\tvalid_0's auc: 0.899771\n",
      "[12000]\tvalid_0's auc: 0.899693\n",
      "Early stopping, best iteration is:\n",
      "[9208]\tvalid_0's auc: 0.899968\n"
     ]
    }
   ],
   "source": [
    "result=np.zeros(test.shape[0])\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,random_state=10)\n",
    "for counter,(train_index, valid_index) in enumerate(rskf.split(train, train.target),1):\n",
    "    print (counter)\n",
    "    \n",
    "    #Train data\n",
    "    t=train.iloc[train_index]\n",
    "    t=augment(t)\n",
    "    trn_data = lgb.Dataset(t.drop(\"target\",axis=1), label=t.target)\n",
    "    \n",
    "    #Validation data\n",
    "    v=train.iloc[valid_index]\n",
    "    val_data = lgb.Dataset(v.drop(\"target\",axis=1), label=v.target)\n",
    "    \n",
    "    #Training\n",
    "    model = lgb.train(param, trn_data, 1000000, valid_sets = [val_data], verbose_eval=500, early_stopping_rounds = 3000)\n",
    "    result += model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/santander-customer-transaction-prediction/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = result/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.078167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.223959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.151597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.206112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.021324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    target\n",
       "0  test_0  0.078167\n",
       "1  test_1  0.223959\n",
       "2  test_2  0.151597\n",
       "3  test_3  0.206112\n",
       "4  test_4  0.021324"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"LightGBM_1NoDataAugExtraFeatFEWERCV.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(path/'sample_submission.csv')\n",
    "\n",
    "filename=\"{:%Y-%m-%d_%H_%M}_sub.csv\".format(datetime.now())\n",
    "submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>r2_var_195</th>\n",
       "      <th>r1_var_195</th>\n",
       "      <th>r2_var_196</th>\n",
       "      <th>r1_var_196</th>\n",
       "      <th>r2_var_197</th>\n",
       "      <th>r1_var_197</th>\n",
       "      <th>r2_var_198</th>\n",
       "      <th>r1_var_198</th>\n",
       "      <th>r2_var_199</th>\n",
       "      <th>r1_var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>7.88</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.56</td>\n",
       "      <td>8.6</td>\n",
       "      <td>12.78</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>...</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.79</td>\n",
       "      <td>8.8</td>\n",
       "      <td>18.36</td>\n",
       "      <td>18.4</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>...</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-6.52</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>8.27</td>\n",
       "      <td>8.3</td>\n",
       "      <td>14.72</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-2.93</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>10.29</td>\n",
       "      <td>10.3</td>\n",
       "      <td>17.97</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-9.00</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3.9</td>\n",
       "      <td>9.50</td>\n",
       "      <td>9.5</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-8.81</td>\n",
       "      <td>-8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target    var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266   \n",
       "1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338   \n",
       "2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155   \n",
       "3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250   \n",
       "4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514   \n",
       "\n",
       "    var_8  ...  r2_var_195  r1_var_195  r2_var_196  r1_var_196  r2_var_197  \\\n",
       "0 -4.9200  ...       -2.40        -2.4        7.88         7.9        8.56   \n",
       "1  3.1468  ...        2.03         2.0        8.13         8.1        8.79   \n",
       "2 -4.9193  ...        3.14         3.1       -6.52        -6.5        8.27   \n",
       "3 -5.8609  ...       -1.27        -1.3       -2.93        -2.9       10.29   \n",
       "4  6.2654  ...       -1.51        -1.5        3.93         3.9        9.50   \n",
       "\n",
       "   r1_var_197  r2_var_198  r1_var_198  r2_var_199  r1_var_199  \n",
       "0         8.6       12.78        12.8       -1.09        -1.1  \n",
       "1         8.8       18.36        18.4        1.95         2.0  \n",
       "2         8.3       14.72        14.7        0.40         0.4  \n",
       "3        10.3       17.97        18.0       -9.00        -9.0  \n",
       "4         9.5       18.00        18.0       -8.81        -8.8  \n",
       "\n",
       "[5 rows x 601 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
